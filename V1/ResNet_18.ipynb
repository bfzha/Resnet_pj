{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c30532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d8469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "LR = 0.1  # SGD\n",
    "# LR = 3e-4 # Adam\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "EPOCHS = 200\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91aff160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:41<00:00, 4.10MB/s] \n"
     ]
    }
   ],
   "source": [
    "# 1.准备数据集\n",
    "MEAN = [0.5070751592371323, 0.48654887331495095, 0.4409178433670343]\n",
    "STD = [0.2673342858792401, 0.2564384629170883, 0.27615047132568404]\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(\n",
    "            p=0.5\n",
    "        ),  # 以0.5的概率水平翻转图像，增加数据多样性\n",
    "        transforms.RandomCrop(\n",
    "            32, padding=4\n",
    "        ),  # 32x32的图像，填充4个像素后再裁剪回32x32 模拟图像小范围位移，提高平移不变性\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02\n",
    "        ),  # 随机调整图像的亮度、对比度、饱和度和色调，增强模型对颜色变化的鲁棒性\n",
    "        transforms.RandomRotation(degrees=9),  # 随机旋转图像，增加模型对旋转的鲁棒性\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0, translate=(0.045, 0.036)\n",
    "        ),  # 随机仿射变换，模拟图像平移\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "        transforms.RandomErasing(\n",
    "            p=0.25, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=\"random\"\n",
    "        ),  # 随机擦除图像的一部分，模拟遮挡情况，增强模型的鲁棒性\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(MEAN, STD)]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=\"../datasets\", train=True, transform=train_transform, download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"../datasets\", train=False, transform=test_transform, download=True\n",
    ")\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59717e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义残差块 较低深度的ResNet使用BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1  # 每个残差块输出通道数与输入通道数的扩展倍数\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_planes,\n",
    "                    self.expansion * planes,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(self.expansion * planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064e75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.定义ResNet-18模型\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, 64, num_blocks[0], stride=1\n",
    "        )  # 3x32x32 → 64x32x32\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, 128, num_blocks[1], stride=2\n",
    "        )  # 64x32x32 → 128x16x16\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, 256, num_blocks[2], stride=2\n",
    "        )  # 128x16x16 → 256x8x8\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, 512, num_blocks[3], stride=2\n",
    "        )  # 256x8x8 → 512x4x4\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # 3×32×32 → 64×32×32\n",
    "        x = self.layer1(x)  # 64×32×32 → 64×32×32\n",
    "        x = self.layer2(x)  # 64×32×32 → 128×16×16\n",
    "        x = self.layer3(x)  # 128×16×16 → 256×8×8\n",
    "        x = self.layer4(x)  # 256×8×8 → 512×4×4\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ResNet18(BasicBlock, [2, 2, 2, 2], NUM_CLASSES).to(\n",
    "    DEVICE\n",
    ")  # 每层的残差块数量（2+2+2+2=8个块 × 2层/块 = 16个卷积层 + 1个初始卷积 = 17层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab75f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[100, 150, 175], gamma=0.1\n",
    ")\n",
    "\n",
    "# 余弦退火 可选\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "685983b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d76f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.测试模型\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = 100 * correct / total\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797cbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.绘图\n",
    "def plot(train_loss, train_acc, test_loss, test_acc):\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # 损失对比图\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, \"b-\", label=\"Training Loss\", alpha=0.7)\n",
    "    plt.plot(epochs, test_loss, \"r-\", label=\"Test Loss\", alpha=0.7)\n",
    "    plt.title(\"Training vs Test Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # 准确率对比图\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc, \"b-\", label=\"Training Accuracy\", alpha=0.7)\n",
    "    plt.plot(epochs, test_acc, \"r-\", label=\"Test Accuracy\", alpha=0.7)\n",
    "    plt.title(\"Training vs Test Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be8d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: Train Loss: 1.8696, Train Acc: 31.26%, Test Loss: 1.5447, Test Acc: 42.36%\n",
      "New best model saved with accuracy: 42.36%\n",
      "Epoch 2/200: Train Loss: 1.4698, Train Acc: 45.82%, Test Loss: 1.3223, Test Acc: 52.34%\n",
      "New best model saved with accuracy: 52.34%\n",
      "Epoch 3/200: Train Loss: 1.2176, Train Acc: 56.51%, Test Loss: 1.2888, Test Acc: 56.42%\n",
      "New best model saved with accuracy: 56.42%\n",
      "Epoch 4/200: Train Loss: 1.0455, Train Acc: 62.98%, Test Loss: 0.9559, Test Acc: 66.42%\n",
      "New best model saved with accuracy: 66.42%\n",
      "Epoch 5/200: Train Loss: 0.9109, Train Acc: 68.07%, Test Loss: 0.9609, Test Acc: 66.37%\n",
      "Epoch 6/200: Train Loss: 0.8055, Train Acc: 71.83%, Test Loss: 0.7779, Test Acc: 74.04%\n",
      "New best model saved with accuracy: 74.04%\n",
      "Epoch 7/200: Train Loss: 0.7393, Train Acc: 74.33%, Test Loss: 0.8117, Test Acc: 72.96%\n",
      "Epoch 8/200: Train Loss: 0.6877, Train Acc: 76.16%, Test Loss: 0.7273, Test Acc: 75.21%\n",
      "New best model saved with accuracy: 75.21%\n",
      "Epoch 9/200: Train Loss: 0.6626, Train Acc: 77.12%, Test Loss: 0.6577, Test Acc: 77.30%\n",
      "New best model saved with accuracy: 77.30%\n",
      "Epoch 10/200: Train Loss: 0.6358, Train Acc: 77.97%, Test Loss: 0.6808, Test Acc: 77.09%\n",
      "Epoch 11/200: Train Loss: 0.6139, Train Acc: 78.91%, Test Loss: 0.7028, Test Acc: 76.72%\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"model_v\", exist_ok=True)\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # 初始化历史记录列表\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = train(epoch)\n",
    "        test_loss, test_acc = test(epoch)\n",
    "        scheduler.step()  # 更新学习率\n",
    "\n",
    "        # 记录历史数据\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{EPOCHS}: \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "            f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        if test_acc > best_accuracy:\n",
    "            best_accuracy = test_acc\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"accuracy\": test_acc,\n",
    "                },\n",
    "                f\"model_v/best_model.pth\",\n",
    "            )\n",
    "            print(f\"New best model saved with accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Training completed! Best accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "    plot(train_losses, train_accs, test_losses, test_accs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision-transformers-cifar10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
